{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['SPARK_HOME'] = 'C:\\spark'\n",
    "os.environ['HADOOP_HOME'] = 'C:\\spark\\hadoop'\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName('Modelo_Recomendacao')\\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = spark.read.parquet('DADOS/dataset_preparado')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vetorização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "x = dados.columns\n",
    "x.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=x, outputCol='features')\n",
    "dados_treino = assembler.transform(dados).select(['features'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures')\n",
    "scaler_model = scaler.fit(dados_treino)\n",
    "dados_scaler = scaler_model.transform(dados_treino)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recução da Dimensionalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=2, inputCol='scaledFeatures', outputCol='pca_features')\n",
    "model_pca = pca.fit(dados_scaler)\n",
    "dados_pca = model_pca.transform(dados_scaler)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline = Pipeline(stages=[assembler, scaler, pca])\n",
    "pca_pipeline_model = pca_pipeline.fit(dados)\n",
    "dados_pca = pca_pipeline_model.transform(dados)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusterizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "SEED = 1224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_kmeans = KMeans(featuresCol='pca_features',predictionCol='cluster_pca', k=5, seed=SEED)\n",
    "model_kmeans = cluster_kmeans.fit(dados_pca)\n",
    "predictions_kmeans = model_kmeans.transform(dados_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----------+\n",
      "|pca_features                             |cluster_pca|\n",
      "+-----------------------------------------+-----------+\n",
      "|[-5.512118758465008,-0.43476839552976954]|0          |\n",
      "|[-4.8256678817413174,-0.5295971192273197]|3          |\n",
      "|[-4.316107109820567,-0.7522300656417595] |3          |\n",
      "|[-5.389508969071561,-0.27188950959557334]|0          |\n",
      "|[-5.509200590399002,-0.4352124273782808] |0          |\n",
      "+-----------------------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions_kmeans.select(\n",
    "    'pca_features', 'cluster_pca').show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|cluster_pca|count|\n",
      "+-----------+-----+\n",
      "|          1| 8472|\n",
      "|          3|14760|\n",
      "|          4|17437|\n",
      "|          2| 5127|\n",
      "|          0|20541|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_kmeans.select('cluster_pca').groupBy('cluster_pca').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------------+-----------------+-------------+-----------+---------------+------------+------------------+------------------+\n",
      "|cluster_pca|quantidade|       valor_medio|       area_media|quartos_medio|vagas_medio|banheiros_medio|suites_medio|  condominio_medio|        iptu_medio|\n",
      "+-----------+----------+------------------+-----------------+-------------+-----------+---------------+------------+------------------+------------------+\n",
      "|          0|     20541| 863595.3336254321|90.76690521396232|          2.0|        1.0|            2.0|         1.0| 4356.066160362202| 3676.753955503627|\n",
      "|          1|      8472|2646218.1606468367|204.4748583569405|          4.0|        2.0|            4.0|         2.0| 6477.303706326723|12652.581090651558|\n",
      "|          2|      5127| 3893152.328067096|285.2802808660035|          4.0|        3.0|            5.0|         3.0| 16801.08991613029|15630.653013458163|\n",
      "|          3|     14760| 793718.8814363143|82.92960704607046|          2.0|        1.0|            2.0|         1.0|3374.4650406504065|2036.6097560975609|\n",
      "|          4|     17437| 802345.9217755347|83.72856569363996|          2.0|        1.0|            2.0|         0.0|1662.9263634799563|1733.2756208063313|\n",
      "+-----------+----------+------------------+-----------------+-------------+-----------+---------------+------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Função copiada da instrutora, achei muito interessante a forma como ela fez a contagem dos dados.\n",
    "\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "dados_pca\\\n",
    "    .join(predictions_kmeans.select('id', 'cluster_pca'), on='id')\\\n",
    "    .groupBy('cluster_pca')\\\n",
    "    .agg(\n",
    "        f.count('id').alias('quantidade'),\n",
    "        f.mean('valor').alias('valor_medio'),\n",
    "        f.mean('area_util').alias('area_media'),\n",
    "        f.round(f.mean('quartos'), 0).alias('quartos_medio'),\n",
    "        f.round(f.mean('vaga'), 0).alias('vagas_medio'),\n",
    "        f.round(f.mean('banheiros'), 0).alias('banheiros_medio'),\n",
    "        f.round(f.mean('suites'), 0).alias('suites_medio'),\n",
    "        f.mean('condominio').alias('condominio_medio'),\n",
    "        f.mean('iptu').alias('iptu_medio'),\n",
    "    )\\\n",
    "    .orderBy('cluster_pca')\\\n",
    "    .show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline_model.stages[2].explainedVariance\n",
    "k = len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=k, inputCol='scaledFeatures', outputCol='pca_features')\n",
    "model_pca = pca.fit(dados_pca.drop('pca_features'))\n",
    "dados_imoveis_pca = model_pca.transform(dados_pca.drop('pca_features'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model_pca.explainedVariance) * 100\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor Dimensionalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lista_valores = np.cumsum(model_pca.explainedVariance[:])\n",
    "k = int(sum(lista_valores <= 0.7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=k, inputCol='scaledFeatures', outputCol='pca_features')\n",
    "model_pca = pca.fit(dados_pca.drop('pca_features'))\n",
    "dados_imoveis_pca_final = model_pca.transform(dados_pca.drop('pca_features'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline = Pipeline(stages=[assembler, scaler, pca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca_pipeline = pca_pipeline.fit(dados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = model_pca_pipeline.transform(dados)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "silhouette_score = []\n",
    "\n",
    "evaluator = ClusteringEvaluator(predictionCol='cluster_pca', featuresCol='pca_features',\n",
    "                                metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "silhouette_score = {}\n",
    "\n",
    "for i in range(2, 51):\n",
    "\n",
    "    KMeans_algo = KMeans(k=i, featuresCol='pca_features',\n",
    "                         predictionCol='cluster_pca', seed=SEED)\n",
    "\n",
    "    KMeans_fit = KMeans_algo.fit(projection)\n",
    "\n",
    "    output = KMeans_fit.transform(projection)\n",
    "\n",
    "    score = evaluator.evaluate(output)\n",
    "    silhouette_score[i] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_best = [key for key, value in silhouette_score.items() if value ==\n",
    "          max(silhouette_score.values())]\n",
    "k_best[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=k_best[0], featuresCol='pca_features',\n",
    "                predictionCol='cluster_pca', seed=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_kmeans = kmeans.fit(projection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "projetion_kmeans = modelo_kmeans.transform(projection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "projetion_kmeans.write.parquet('DADOS/dataset_projecao_kmeans', mode='overwrite')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação das Funções de Consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_imovel = '0034df72-124a-4383-a89f-a019850a2ba0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "  cluster = projetion_kmeans.filter(\n",
    "    projetion_kmeans.id == id_imovel).select('cluster_pca').collect()[0][0]\n",
    "  cluster\n",
    "except:\n",
    "    print(\"Não foi possível encotnrar o imóvel com o id informado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  id|        pca_features|\n",
      "+--------------------+--------------------+\n",
      "|34aea9e8-cd98-4a0...|[-4.4914908601853...|\n",
      "|d6c67f6b-5515-4f6...|[-4.4284664548113...|\n",
      "|a6385b02-8349-409...|[-4.5494351090068...|\n",
      "|cca0dbb3-7c52-4ed...|[-4.3805173611370...|\n",
      "|6b6c2bee-793b-473...|[-4.4546925726016...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imoveis_recomendadas = projetion_kmeans.filter(projetion_kmeans.cluster_pca == cluster)\\\n",
    "                                       .select('id', 'pca_features')\n",
    "imoveis_recomendadas.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-4.6145, -4.0154, 1.3826, 0.2565, -0.0629, 0.3156])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imovel_procurado = imoveis_recomendadas.filter(imoveis_recomendadas.id == id_imovel)\\\n",
    "    .select('pca_features').collect()[0][0]\n",
    "imovel_procurado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from pyspark.sql.types import FloatType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                  id| distancia|\n",
      "+--------------------+----------+\n",
      "|0034df72-124a-438...|       0.0|\n",
      "|e5ec2e28-c81f-47a...| 0.1730086|\n",
      "|12012273-e197-488...| 0.1799632|\n",
      "|c4585166-c411-4e5...|0.18049306|\n",
      "|acbccbb4-4aec-452...| 0.2254096|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_euclidean_distance(imovel, valor):\n",
    "    return euclidean(imovel, valor)\n",
    "\n",
    "\n",
    "euclidean_udf = f.udf(lambda x: calculate_euclidean_distance(\n",
    "    imovel_procurado, x), FloatType())\n",
    "\n",
    "imoveis_recomendadas\\\n",
    "    .withColumn('distancia', euclidean_udf('pca_features'))\\\n",
    "    .select('id', 'distancia')\\\n",
    "    .orderBy('distancia')\\\n",
    "    .show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_euclidean_distance(imovel, valor):\n",
    "    return euclidean(imovel, valor)\n",
    "\n",
    "\n",
    "def recommender(id_imovel, dataframe_kmeans):\n",
    "    cluster = dataframe_kmeans\\\n",
    "        .filter(dataframe_kmeans.id == id_imovel)\\\n",
    "        .select('cluster_pca')\\\n",
    "        .collect()[0][0]\n",
    "\n",
    "    imoveis_recomendadas = dataframe_kmeans\\\n",
    "        .filter(dataframe_kmeans.cluster_pca == cluster)\n",
    "\n",
    "    imovel_procurado = imoveis_recomendadas\\\n",
    "        .filter(imoveis_recomendadas.id == id_imovel)\\\n",
    "        .select('pca_features')\\\n",
    "        .collect()[0][0]\n",
    "\n",
    "    euclidean_udf = f.udf(lambda x: calculate_euclidean_distance(\n",
    "        imovel_procurado, x), FloatType())\n",
    "\n",
    "    colunas_nao_utilizadas = [\n",
    "        'features', 'scaled_features', 'pca_features', 'cluster_pca', 'distancia']\n",
    "\n",
    "    recomendadas = imoveis_recomendadas\\\n",
    "        .withColumn('distancia', euclidean_udf('pca_features'))\\\n",
    "        .select([col for col in imoveis_recomendadas.columns if col not in colunas_nao_utilizadas])\\\n",
    "        .orderBy('distancia')\n",
    "\n",
    "    return recomendadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|id                                  |\n",
      "+------------------------------------+\n",
      "|0034df72-124a-4383-a89f-a019850a2ba0|\n",
      "|e5ec2e28-c81f-47a6-aeff-1288d6773c7b|\n",
      "|12012273-e197-488f-bf81-784cb02ec875|\n",
      "|c4585166-c411-4e57-9095-9b7ac2f5dccc|\n",
      "|acbccbb4-4aec-4527-88fa-7933de023633|\n",
      "|a5ff60b0-bc83-4e98-b56f-3e855b7b3711|\n",
      "|7e96df1b-e77d-49c5-82e2-cc5ac4f6f960|\n",
      "|d155b386-04e3-48e1-9bb1-f6f14a84a675|\n",
      "|612f2a2c-a28a-44ec-b6d1-4d7606932f84|\n",
      "|dbe16cf4-439c-4812-9233-34507b399d53|\n",
      "|7c3e3897-3734-4a10-bd7f-2efbb28aaef8|\n",
      "|5788a47e-04e1-41fd-8d81-dfaeff13d942|\n",
      "|9f12771a-93e0-4fe6-bfd2-02d40e429644|\n",
      "|a6b8131b-9bec-46cd-83a7-aa491b83dbe1|\n",
      "|5cbe6ea9-ae38-4f19-8f45-c5f75431b9cd|\n",
      "|ef6cf68f-ea1a-46c2-aeb4-84e3a4822b51|\n",
      "|e1302c47-8a02-4044-92db-7975d743caa6|\n",
      "|e8d36b03-9a0b-47cf-aed2-01b063fa07f0|\n",
      "|0c7b4266-d8fd-4cf2-95d8-d0ba4121feb9|\n",
      "|c3f03e00-b8f8-4b28-9e4c-2590b0d1b083|\n",
      "+------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommender(\"0034df72-124a-4383-a89f-a019850a2ba0\",\n",
    "            projetion_kmeans).select(\"id\").show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f42f955e7f8da3c548e302e1e5347a7e875359e0d4da102c4592ccaca30f562a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
